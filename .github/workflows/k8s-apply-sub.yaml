name: K8s Apply (sub)

on: 
  workflow_call:
    inputs:
      environment:
        description: 'Environment to run apply against'
        required: true
        type: string
      timeout_seconds:
        description: 'Kubectl apply wait timeout in seconds for Deployments'
        required: true
        type: number
    secrets:
      AWS_REGION:
        required: true
      EKS_CLUSTER_NAME:
        required: true

defaults:
  run:
    shell: bash

env:
  SCRIPTS_FOLDER: "./interop-infra-commons/scripts/helm"

jobs:
  initChecks:
    runs-on: ubuntu-22.04
    environment: ${{ inputs.environment }}
    steps:
      - name: Check user is a ${{ vars.ALLOWED_DEPLOY_GH_TEAMS }} team member
        id: checkUserPermissions
        if: ${{ inputs.environment != 'dev' }}
        env:
            GITHUB_TOKEN: ${{ secrets.BOT_TEAMS_RO_PAT }}
            ORG: ${{ github.repository_owner }}
            TEAMS: ${{ vars.ALLOWED_DEPLOY_GH_TEAMS }}
            USER: ${{ github.triggering_actor	}}
        run: |
          set -euo pipefail
          TEAMS_LIST=$(echo $TEAMS | tr "," "\n")

          CHECK_SUCCESS=0

          for TEAM in $TEAMS_LIST; do
            set +e
            # Check current user membership with gh api 
            echo "Check if user is member of $TEAM"           
            GH_TEAM_MEMBERSHIP_RESPONSE=$(gh api -i --method GET -H "Accept: application/vnd.github+json" -H "X-GitHub-Api-Version: 2022-11-28" \/orgs/$ORG/teams/$TEAM/memberships/$USER)
            set -e
            
            # Extract the HTTP status code
            HTTP_CODE=$(echo $GH_TEAM_MEMBERSHIP_RESPONSE | head -n 1 | cut -d' ' -f 2)

            if [[ $HTTP_CODE -eq 200 ]]; then
              echo "User is member of $TEAM"
              CHECK_SUCCESS=1
              break
            else
              echo "User is NOT member of $TEAM"
            fi
          done
            
          if [[ $CHECK_SUCCESS -eq 0 ]]; then
            echo "::error:: Resource not found. Please check the organization ($ORG), team ($TEAMS), and username ($USER). $USER is not memeber of specified teams."
            exit 1
          fi

          echo "$USER has the correct permissions to execute the workflow."
  workflow_setup:
    name: Setup steps
    needs: [ initChecks ]
    runs-on: [ self-hosted, "run_id:${{ inputs.environment }}-${{ github.run_id }}" ]
    environment: ${{ inputs.environment }}
    env:
      TARGET_ENVIRONMENT: ${{ inputs.environment }}
    outputs:
      microservices: ${{ steps.set-outputs.outputs.microservices }}
      cronjobs: ${{ steps.set-outputs.outputs.cronjobs }}
    steps:
      - name: Checkout
        id: checkout
        uses: actions/checkout@a5ac7e51b41094c92402da3b24376905380afc29
      - id: set-outputs
        run: |
          echo "microservices=$(find microservices -type f -path "*/$TARGET_ENVIRONMENT/values.yaml" -exec dirname {} \; | awk -F'/' '{print $2}' | jq -R -s -c 'split("\n")[:-1]')" >> "$GITHUB_OUTPUT"
          echo "cronjobs=$(find jobs -type f -path "*/$TARGET_ENVIRONMENT/values.yaml" -exec dirname {} \; | awk -F'/' '{print $2}' | jq -R -s -c 'split("\n")[:-1]')" >> "$GITHUB_OUTPUT"

  deploy_common_configmaps:
    name: Deploy Common Configmaps
    needs: [ workflow_setup ]
    runs-on: [ self-hosted, "run_id:${{ inputs.environment }}-${{ github.run_id }}" ]
    environment: ${{ inputs.environment }}
    steps:
      - name: Checkout
        id: checkout
        uses: actions/checkout@a5ac7e51b41094c92402da3b24376905380afc29
      - name: Update Kubeconfig
        id: update_kubeconfig
        run: |
          set -euo pipefail

          aws eks update-kubeconfig --region ${{ secrets.AWS_REGION }} --name ${{ secrets.EKS_CLUSTER_NAME }}
      - name: Apply commons configmaps
        id: apply_commons_configmap
        env:
          ENVIRONMENT: ${{ inputs.environment }}
        run: |
          set -euo pipefail
          
          commons_configmaps_path="commons/$ENVIRONMENT/configmaps"
          
          if [[ -n "$(ls -A $commons_configmaps_path)" ]]; then
            for f in $commons_configmaps_path/*; do
              kubectl apply -f $f
            done;
          fi

  deploy_ms:
    name: ${{ matrix.microservice }}
    runs-on: [ self-hosted, "run_id:${{ inputs.environment }}-${{ github.run_id }}" ]
    environment: ${{ inputs.environment }}
    needs: [workflow_setup, deploy_common_configmaps]
    if: ${{ ! contains(needs.workflow_setup.outputs.microservices, '[]') }}
    strategy:
      matrix:
        microservice: ${{ fromJson(needs.workflow_setup.outputs.microservices) }}
      fail-fast: false
    steps:
      - name: Checkout
        id: checkout
        uses: actions/checkout@a5ac7e51b41094c92402da3b24376905380afc29
      - name: Checkout scripts repository
        uses: actions/checkout@a5ac7e51b41094c92402da3b24376905380afc29
        with:
          repository: pagopa/interop-infra-commons
          path: interop-infra-commons 
          fetch-depth: 0
          sparse-checkout: 'scripts/helm'
          ref: ${{ vars.INFRA_COMMONS_TAG }}
          ssh-key: ${{ secrets.PRIVATE_REPOS_SSH_KEY }}
      - name: Set kubeconfig
        run: |
          aws eks update-kubeconfig --region ${{ secrets.AWS_REGION }} --name ${{ secrets.EKS_CLUSTER_NAME }}
      - name: Deploy
        env:
          MICROSERVICE_NAME: ${{ matrix.microservice }}
          K8S_NAMESPACE: ${{ inputs.environment }}
          TIMEOUT_SECONDS: ${{ inputs.timeout_seconds }}
        run: |
          set -euo pipefail

          $SCRIPTS_FOLDER/kubectlApply-svc-single-standalone.sh --debug --environment $K8S_NAMESPACE -m $MICROSERVICE_NAME --output console 

          CURRENT_SVC=$(kubectl get deployments -n $K8S_NAMESPACE | awk '{if (NR!=1) print $1}' | grep -v grep | grep -i $MICROSERVICE_NAME) 
          
          MAX_WAIT_TIME_SECONDS=$TIMEOUT_SECONDS
          CYCLE_SLEEP_SECONDS=5
          
          CURRENT_DATE_SECONDS=$(date +%s)
          WAIT_EXP_SECONDS=$(($CURRENT_DATE_SECONDS + $MAX_WAIT_TIME_SECONDS))
          SVC_ROLLOUT_STATUS=1

          while [[ $CURRENT_DATE_SECONDS -lt $WAIT_EXP_SECONDS ]]
          do
            set +e
            kubectl rollout status -n $K8S_NAMESPACE deployment/$CURRENT_SVC > /dev/null
            SVC_ROLLOUT_STATUS=$?
            set -e
            
            if [[ $SVC_ROLLOUT_STATUS  -eq 0 ]]; then
              echo "INFO -" $CURRENT_SVC "deployed"
              break
            else
              echo  "::warning::WARNING - " $CURRENT_SVC  "not yet deployed"
            fi
            
            sleep $CYCLE_SLEEP_SECONDS
            CURRENT_DATE_SECONDS=$(date +%s)
          done

          exit $SVC_ROLLOUT_STATUS

  deploy_cj:
    name: ${{ matrix.cronjob }}
    runs-on: [ self-hosted, "run_id:${{ inputs.environment }}-${{ github.run_id }}" ]
    environment: ${{ inputs.environment }}
    needs: [workflow_setup, deploy_common_configmaps]
    if: ${{ ! contains(needs.workflow_setup.outputs.cronjobs, '[]') }}
    strategy:
      matrix:
        cronjob: ${{ fromJson(needs.workflow_setup.outputs.cronjobs) }}
      fail-fast: false
    steps:
      - name: Checkout
        id: checkout
        uses: actions/checkout@a5ac7e51b41094c92402da3b24376905380afc29
      - name: Checkout scripts repository
        uses: actions/checkout@a5ac7e51b41094c92402da3b24376905380afc29
        with:
          repository: pagopa/interop-infra-commons
          path: interop-infra-commons 
          fetch-depth: 0
          sparse-checkout: 'scripts/helm'
          ref: ${{ vars.INFRA_COMMONS_TAG }}
          ssh-key: ${{ secrets.PRIVATE_REPOS_SSH_KEY }}
      - name: Set kubeconfig
        run: |
          aws eks update-kubeconfig --region ${{ secrets.AWS_REGION }} --name ${{ secrets.EKS_CLUSTER_NAME }}
      - name: Deploy
        env:
          CRONJOB_NAME: ${{ matrix.cronjob }}
          K8S_NAMESPACE: ${{ inputs.environment }}
        run: |
          set -euo pipefail

          $SCRIPTS_FOLDER/kubectlApply-cron-single-standalone.sh --debug --environment $K8S_NAMESPACE -j $CRONJOB_NAME --output console 
